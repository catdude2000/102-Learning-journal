# Implementation: Linked Lists

## Resources

### [Big O: Analysis of Algorithm Efficiency](https://codefellows.github.io/common_curriculum/data_structures_and_algorithms/Code_401/class-05/resources/big_oh.html) (Up through the section titled “Linear Complexity Growth”)

"Running Time (also known as **time** efficiency / complexity)  
The amount of time a function needs to complete."  
"Memory Space (also known as **space** efficiency / complexity)  
The amount of memory resources a function uses to store data and instructions."  
Big O describes worst case.  
4 key areas for analysis:  

1. Input Size (letter n)  
2. Units of Measurement  
"The time in **milliseconds**...
For the purposes of Big O, we won’t be considering this measurement... Regardless, this will always be a measurement of run-time.

The number of **operations** that are executed...

The number of **“Basic Operations”** that are executed.
“Basic Operation” refers to the operation that is contributing the most to the total running time."  
3. Orders of Growth  
"...Order of Growth represents the increase in **Running Time** or **Memory Space**."  
![Orders Of Growth](assets/OrdersOfGrowth.png)  
"**Constant Complexity** means that no matter what inputs are thrown at our algorithm, it always uses the same amount of time or space. The number 1 is used to represent a constant value."  
"Logarithmic Complexity represents a function that sees a decrease in the rate of complexity growth, the greater our value of n."  
4. Best Case, Worst Case, and Average Case  

- "Big O(oh): This notation describes the Worst Case (The efficiency for the worst possible input of size n) for an algorithm. The Order of Growth used represents the upper bounds of Time and Space.
- Big Omega: This notation describes the Best Case (The efficiency for the best possible input of size n) for a given algorithm. The Order of Growth used represents the lower bounds of Time and Space.
- Big Theta: This notation describes the Average Case. (The efficiency for a “typical” or “random” input of size n.) The Order of Growth used represents the tight bound of Time and Space."  

### [Linked Lists](https://codefellows.github.io/common_curriculum/data_structures_and_algorithms/Code_401/class-05/resources/singly_linked_list.html)

Linked list is a sequence of nodes that are linked, with each node referencing the next.  
Two types: Singly and Doubly, referring to how many references to another node there are.  Singly refers only to next, doubly refers to previous and next.  
"When traversing a linked list, you are not able to use a foreach or for loop. We depend on the Next value..." Use while loop.  
"...trying to traverse on a node that is null, a NullReferenceException gets thrown and our program will crash/end."  

### [What’s a Linked List, Anyway pt1](https://medium.com/basecs/whats-a-linked-list-anyway-part-1-d8b7e6508b9d)

Linked lists are linear data structures.  
Don't need single blovk of memory, can be scattered.  
"...difference between arrays and linked lists is that arrays are static data structures, (always needs a given size and amount of memory) while linked lists are dynamic data structures." (can shrink and grow in memory)  
Node reference allows data to be scattered.  
"A circular linked list is a little odd in that it doesn’t end with a node pointing to a null value. Instead, it has a node that acts as the tail of the list (rather than the conventional head node), and the node after the tail node is the beginning of the list."  

### [What’s a Linked List, Anyway pt2](https://medium.com/basecs/whats-a-linked-list-anyway-part-2-131d96f71996)

Grow a linked list by rearranging pointers.  
"a linked list is usually efficient when it comes to adding and removing most elements, but can be very slow to search and find a single element."  

- [Go to TOC](README.md)
